{
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppy7so3HYiOK"
      },
      "source": [
        "# Multimodal Mountain Peak Search — Colab Quickstart (Navneet)\n",
        "\n",
        "This notebook shows how to:\n",
        "- Install deps\n",
        "- Connect to **Elasticsearch**\n",
        "- Create indices\n",
        "- Index a small **peaks catalog** (text+image blended vectors)\n",
        "- Index a few **photos**\n",
        "- Run **text → image** search and **identify-from-photo** search\n",
        "\n",
        "> Minimal demo for the LinkedIn/blog post. No Streamlit here; it’s pure Python cells so anyone can run it in Colab.\n"
      ],
      "id": "ppy7so3HYiOK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABMvzs64YiOL"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install elasticsearch pillow pillow-heif PyYAML transformers huggingface-hub \\\n",
        "                torch torchvision folium streamlit-folium\n",
        "print(\"✅ Installed\")"
      ],
      "id": "ABMvzs64YiOL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0tHMSj6YiOM",
        "outputId": "57a24ffc-26d3-43c2-8a14-24376d4c9400"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ES_URL     : http://localhost:9200\n",
            "CLOUD_ID?  : False\n",
            "API_KEY_B64: MISSING\n"
          ]
        }
      ],
      "source": [
        "#@title Configure Elasticsearch (API key recommended)\n",
        "import os, base64\n",
        "\n",
        "# 👉 Set ONE of these:\n",
        "ES_URL = os.environ.get(\"ES_URL\", \"http://localhost:9200\")      # if you have a local ES tunnel\n",
        "ES_CLOUD_ID = os.environ.get(\"ES_CLOUD_ID\", \"\")                 # if using Elastic Cloud\n",
        "\n",
        "# Option A: single base64 api key (id:key base64-encoded)\n",
        "ES_API_KEY_B64 = os.environ.get(\"ES_API_KEY_B64\", \"\")\n",
        "\n",
        "# Option B: id + key (assemble and base64-encode)\n",
        "ES_API_KEY_ID  = os.environ.get(\"ES_API_KEY_ID\", \"\")\n",
        "ES_API_KEY     = os.environ.get(\"ES_API_KEY\", \"\")\n",
        "\n",
        "if not ES_API_KEY_B64 and (ES_API_KEY_ID and ES_API_KEY):\n",
        "    ES_API_KEY_B64 = base64.b64encode(f\"{ES_API_KEY_ID}:{ES_API_KEY}\".encode()).decode()\n",
        "\n",
        "print(\"ES_URL     :\", ES_URL)\n",
        "print(\"CLOUD_ID?  :\", bool(ES_CLOUD_ID))\n",
        "print(\"API_KEY_B64:\", \"set\" if ES_API_KEY_B64 else \"MISSING\")\n",
        "\n",
        "# Propagate for scripts\n",
        "os.environ[\"ES_URL\"] = ES_URL\n",
        "os.environ[\"ES_CLOUD_ID\"] = ES_CLOUD_ID\n",
        "os.environ[\"ES_API_KEY_B64\"] = ES_API_KEY_B64\n",
        "\n",
        "# Optional model override\n",
        "# os.environ[\"SIGLIP_MODEL_ID\"] = \"google/siglip-so400m-patch14-384\"\n"
      ],
      "id": "o0tHMSj6YiOM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za6W0opPYiOM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Clone your repo\n",
        "REPO_URL = \"https://github.com/navneet83/multimodal-mountain-peak-search\"\n",
        "TARGET_DIR = \"/content/multimodal-mountain-peak-search\"\n",
        "import os, shutil, subprocess, sys\n",
        "\n",
        "if os.path.exists(TARGET_DIR):\n",
        "    shutil.rmtree(TARGET_DIR)\n",
        "\n",
        "print(\"Cloning:\", REPO_URL)\n",
        "rc = subprocess.call([\"git\",\"clone\",\"--depth\",\"1\", REPO_URL, TARGET_DIR])\n",
        "if rc != 0:\n",
        "    raise SystemExit(\"❌ Clone failed. Check the repo URL or network.\")\n",
        "\n",
        "os.chdir(TARGET_DIR)\n",
        "sys.path.insert(0, os.path.join(TARGET_DIR, \"src\"))  # import ai_mpi.embeddings\n",
        "print(\"✅ Cloned and cwd set to\", TARGET_DIR)"
      ],
      "id": "za6W0opPYiOM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T5tDn7ZYiOO"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Create indices in Elasticsearch\n",
        "!python scripts/create_indices.py --recreate || python scripts/create_indices.py\n",
        "print(\"✅ Indices ready\")"
      ],
      "id": "6T5tDn7ZYiOO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6MFsDyYiOP"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Index peaks (blended text + reference images)\n",
        "!python scripts/embed_and_index_photos.py --index-peaks --peaks-yaml data/peaks.yaml --peaks-images-root data/peaks --blend-alpha-text 0.55 --blend-max-images 3\n",
        "print(\"✅ Peaks indexed\")"
      ],
      "id": "tk6MFsDyYiOP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXsTSmGpYiOP"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Photos to index: upload or reuse repo samples\n",
        "from google.colab import files\n",
        "import shutil, os, glob\n",
        "\n",
        "USE_REPO_SAMPLE = True  #@param {type:\"boolean\"}\n",
        "MAX_COPY = 1            #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "os.makedirs(\"data/images\", exist_ok=True)\n",
        "\n",
        "if USE_REPO_SAMPLE:\n",
        "    # Reuse any images already in repo (data/images or data/peaks/*)\n",
        "    copied = 0\n",
        "    existing = glob.glob(\"data/images/*\")\n",
        "    if not existing:\n",
        "        for pdir in glob.glob(\"data/peaks/*\"):\n",
        "            for fp in glob.glob(os.path.join(pdir, \"*\")):\n",
        "                base = os.path.basename(fp)\n",
        "                dst = os.path.join(\"data/images\", base)\n",
        "                if not os.path.exists(dst):\n",
        "                    try:\n",
        "                        shutil.copy(fp, dst)\n",
        "                        copied += 1\n",
        "                        if copied >= MAX_COPY:\n",
        "                            break\n",
        "                    except Exception:\n",
        "                        pass\n",
        "            if copied >= MAX_COPY:\n",
        "                break\n",
        "    print(f\"✅ Using repo images. Added {copied} files (or existing ones).\")\n",
        "else:\n",
        "    print(\"📤 Upload 3–10 JPG/PNG/HEIC images (keeps the demo snappy).\")\n",
        "    uploads = files.upload()\n",
        "    for name in uploads.keys():\n",
        "        shutil.move(name, f\"data/images/{name}\")\n",
        "\n",
        "!find data/images -maxdepth 1 -type f -print || true\n"
      ],
      "id": "xXsTSmGpYiOP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualslgxsYiOP"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Index your photos\n",
        "!python scripts/embed_and_index_photos.py --index-photos --images data/images --topk-predicted 5\n",
        "print(\"✅ Photos indexed\")"
      ],
      "id": "ualslgxsYiOP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwdDuBp-YiOQ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Text → image search (type a peak name)\n",
        "from elasticsearch import Elasticsearch\n",
        "from ai_mpi.embeddings import Siglip2\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "import os\n",
        "\n",
        "def es_client():\n",
        "    cloud_id = os.getenv(\"ES_CLOUD_ID\",\"\")\n",
        "    url      = os.getenv(\"ES_URL\",\"http://localhost:9200\")\n",
        "    api_b64  = os.getenv(\"ES_API_KEY_B64\",\"\")\n",
        "    if cloud_id:\n",
        "        return Elasticsearch(cloud_id=cloud_id, api_key=api_b64 if api_b64 else None)\n",
        "    return Elasticsearch(url, api_key=api_b64 if api_b64 else None)\n",
        "\n",
        "es = es_client()\n",
        "emb = Siglip2()\n",
        "PHOTOS_INDEX = os.getenv(\"PHOTOS_INDEX\",\"photos\")\n",
        "\n",
        "def l2norm(v):\n",
        "    v = np.asarray(v, dtype=np.float32)\n",
        "    return v/(np.linalg.norm(v)+1e-12)\n",
        "\n",
        "def prompt_vec(peak_name: str):\n",
        "    prompts = [\n",
        "        f\"a natural photo of the mountain peak {peak_name} in the Himalayas, Nepal\",\n",
        "        f\"{peak_name} landmark peak in the Khumbu region, alpine landscape\",\n",
        "        f\"{peak_name} mountain summit, snow, rocky ridgeline\",\n",
        "    ]\n",
        "    proto = sum([emb.text_vec(p) for p in prompts]) / 3.0\n",
        "    anti  = emb.text_vec(\"painting, illustration, poster, map, logo\")\n",
        "    return l2norm(proto - 0.25*anti).astype(\"float32\")\n",
        "\n",
        "query = \"Pumori\"  #@param [\"Ama Dablam\", \"Pumori\", \"Mount Everest\"] {allow-input: true}\n",
        "k = 12  #@param {type:\"slider\", min:6, max:30, step:2}\n",
        "\n",
        "qvec = prompt_vec(query)\n",
        "resp = es.search(index=PHOTOS_INDEX, body={\n",
        "    \"knn\": {\"field\":\"clip_image\", \"query_vector\": qvec.tolist(), \"k\": int(k), \"num_candidates\": 1000},\n",
        "    \"_source\": [\"path\",\"predicted_peaks\",\"clip_image\",\"shot_time\",\"gps\"]\n",
        "})\n",
        "hits = resp.get(\"hits\",{}).get(\"hits\",[])\n",
        "\n",
        "print(f\"Top {len(hits)} results for “{query}”\")\n",
        "cards = []\n",
        "for h in hits:\n",
        "    s = h.get(\"_source\",{})\n",
        "    score = h.get(\"_score\", 0.0)\n",
        "    path = s.get(\"path\")\n",
        "    preds = \", \".join(s.get(\"predicted_peaks\", [])[:2])\n",
        "    ts = (s.get(\"shot_time\") or \"\").split(\"T\")[0]\n",
        "    cards.append(f\"<div style='display:inline-block;margin:6px;text-align:center'>\"\n",
        "                 f\"<img src='data/images/{path}' width='220'/><br>\"\n",
        "                 f\"<div style='font-size:12px;color:#888'>knn {score:.3f} | {preds} | {ts}</div></div>\")\n",
        "from IPython.display import HTML\n",
        "display(HTML(\"\".join(cards)))"
      ],
      "id": "GwdDuBp-YiOQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl-8A-S3YiOQ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Identify from photo → similar photos (upload OR reuse a repo image)\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import numpy as np, os, glob, shutil\n",
        "from IPython.display import display, HTML\n",
        "from elasticsearch import Elasticsearch\n",
        "from ai_mpi.embeddings import Siglip2\n",
        "\n",
        "PEAKS_INDEX = os.getenv(\"PEAKS_INDEX\",\"peaks_catalog\")\n",
        "PHOTOS_INDEX = os.getenv(\"PHOTOS_INDEX\",\"photos\")\n",
        "\n",
        "def es_client():\n",
        "    cloud_id = os.getenv(\"ES_CLOUD_ID\",\"\")\n",
        "    url      = os.getenv(\"ES_URL\",\"http://localhost:9200\")\n",
        "    api_b64  = os.getenv(\"ES_API_KEY_B64\",\"\")\n",
        "    if cloud_id:\n",
        "        return Elasticsearch(cloud_id=cloud_id, api_key=api_b64 if api_b64 else None)\n",
        "    return Elasticsearch(url, api_key=api_b64 if api_b64 else None)\n",
        "\n",
        "es = es_client()\n",
        "emb = Siglip2()\n",
        "\n",
        "USE_REPO_SAMPLE = False  #@param {type:\"boolean\"}\n",
        "\n",
        "img_path = None\n",
        "if USE_REPO_SAMPLE:\n",
        "    imgs = sorted(glob.glob(\"data/images/*\"))\n",
        "    if imgs:\n",
        "        img_path = imgs[0]\n",
        "    else:\n",
        "        refs = sorted(glob.glob(\"data/peaks/*/*\"))\n",
        "        if refs:\n",
        "            os.makedirs(\"data/images\", exist_ok=True)\n",
        "            dest = os.path.join(\"data/images\", os.path.basename(refs[0]))\n",
        "            shutil.copy(refs[0], dest)\n",
        "            img_path = dest\n",
        "\n",
        "if not img_path:\n",
        "    print(\"📤 Upload ONE image to identify (or set USE_REPO_SAMPLE=True above)\")\n",
        "    uploads = files.upload()\n",
        "    img_path = list(uploads.keys())[0]\n",
        "\n",
        "print(\"Using image:\", img_path)\n",
        "im = Image.open(img_path).convert(\"RGB\")\n",
        "ivec = emb.image_vec(im).astype(\"float32\")\n",
        "\n",
        "# Step 1: image → nearest peaks\n",
        "resp = es.search(index=PEAKS_INDEX, body={\n",
        "    \"knn\": {\"field\":\"text_embed\", \"query_vector\": ivec.tolist(), \"k\": 3, \"num_candidates\": 500},\n",
        "    \"_source\": [\"id\",\"names\",\"text_embed\"]\n",
        "})\n",
        "hits = resp.get(\"hits\",{}).get(\"hits\",[])\n",
        "if not hits:\n",
        "    raise SystemExit(\"No peak guesses; did you index peaks_catalog?\")\n",
        "best = hits[0][\"_source\"]\n",
        "best_name = (best.get(\"names\") or [best.get(\"id\")])[0]\n",
        "print(\"Top guess:\", best_name)\n",
        "\n",
        "# Step 2: use the best peak name → text vector → photos kNN\n",
        "\n",
        "def l2norm(v):\n",
        "    v = np.asarray(v, dtype=np.float32)\n",
        "    return v/(np.linalg.norm(v)+1e-12)\n",
        "\n",
        "def prompt_vec(peak_name: str):\n",
        "    prompts = [\n",
        "        f\"a natural photo of the mountain peak {peak_name} in the Himalayas, Nepal\",\n",
        "        f\"{peak_name} landmark peak in the Khumbu region, alpine landscape\",\n",
        "        f\"{peak_name} mountain summit, snow, rocky ridgeline\",\n",
        "    ]\n",
        "    proto = np.mean([emb.text_vec(p) for p in prompts], axis=0)\n",
        "    anti  = emb.text_vec(\"painting, illustration, poster, map, logo\")\n",
        "    return l2norm(proto - 0.25*anti).astype(\"float32\")\n",
        "\n",
        "qvec = prompt_vec(best_name)\n",
        "resp2 = es.search(index=PHOTOS_INDEX, body={\n",
        "    \"knn\": {\"field\":\"clip_image\", \"query_vector\": qvec.tolist(), \"k\": 12, \"num_candidates\": 1000},\n",
        "    \"_source\": [\"path\",\"predicted_peaks\",\"clip_image\",\"shot_time\",\"gps\"]\n",
        "})\n",
        "hits2 = resp2.get(\"hits\",{}).get(\"hits\",[])\n",
        "\n",
        "cards = [f\"<div style='margin:6px 0;font-weight:600;'>Similar photos for “{best_name}”</div>\"]\n",
        "for h in hits2:\n",
        "    s = h.get(\"_source\",{})\n",
        "    score = h.get(\"_score\", 0.0)\n",
        "    path = s.get(\"path\")\n",
        "    preds = \", \".join(s.get(\"predicted_peaks\", [])[:2])\n",
        "    ts = (s.get(\"shot_time\") or \"\").split(\"T\")[0]\n",
        "    cards.append(f\"<div style='display:inline-block;margin:6px;text-align:center'>\"\n",
        "                 f\"<img src='data/images/{path}' width='220'/><br>\"\n",
        "                 f\"<div style='font-size:12px;color:#888'>knn {score:.3f} | {preds} | {ts}</div></div>\")\n",
        "from IPython.display import HTML\n",
        "display(HTML(\"\".join(cards)))"
      ],
      "id": "bl-8A-S3YiOQ"
    }
  ],
  "metadata": {
    "colab": {
      "name": "02_quickstart_colab_navneet_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  }
}
